% Created 2013-01-28 Mon 22:41
\documentclass[11pt]{article}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage[pdftex]{hyperref}
\usepackage[font=small,labelfont=bf]{caption}
\geometry{a4paper, textwidth=6.5in, textheight=10in, marginparsep=7pt, marginparwidth=.6in}

\title{Data Mining 2013: Project Report}
\author{marinah@student.ethz.ch\\ uvictor@student.ethz.ch\\}
\date{\today}

\begin{document}
\maketitle

\section{Approximate retrieval - Locality Sensitive Hashing}
\begin{enumerate}
\item How was your choice of rows and bands motivated? How did you search for the
best parameters? \\ \\
\textbf{Answer}:

\item Conceptually, what would you have to change if you were asked to design an image
  retrieval system that you can query for similar images given a large image
  dataset? \\

\textbf{Answer}:

We can try to apply the same technique - Locality Sensitive Hashing. We need to
define "shingles" for images. We will call "shingles" for images as visual words. One way to extract visual words is to put a grid over a image and fragment the image in a set of rectangular patches. Now we could represent each image as a set of visual words: the patches extracted from the grid. By doing this we loose
locality information, like the position of the patch in the image, but it 
simplfies dealing with the task.

Now if we consider all distinct visual words to be the shingles, we will probably have very few shingles that occur in multiple images, due to differences in lighting, grid overlay, contrast, etc. One way of extracting better visual words is to clusterize them, using k-means, and use the centers of each cluster as the new visual words. 

After we obtain the visual words by clustering, as described above, we can create the shingle matrix. For each image, we cover it with a grid that fragments the image in rectangular patches. Each patch can be mapped to a nearest visual word
(cluster center). Thus we obtain a set of shingles for each image. Thus similar images should contain similar visual words. It is also more probable that we introduce some false positives. This is because some patches may not be well represented by any of the visual words. To eliminate these, we can set a threshold such that a patch that has similarity to all visual words below a threshold, is not considered for constructing the shingle matrix.

As an example, applying this technique for a set of images containing cars and emtpy streets we would expect that clustering identifies visual words that contain car parts: windows, wheels, doors, and also visual words showing the empty street, etc.

\end{enumerate}

\section{Large-scale Supervised Learning}

\begin{enumerate}
\item Which algorithms did you consider? Which one did you choose for the
  final submission and why? \\ \\
\textbf{Answer}:

First we considered using Online convex programming with training samples picked at random / Stochastic Gradient Descent. We also implemented and run
the PEGASOS algorithm. 

The final solution was using OCP/SGD because it was the one that obtained better scores for our submissions. 

Unfortunately, after the deadline we realised there was a bug in the code that prevented both PEGASOS and OCP/SGD from running correctly. The problem
was the random shuffling of the order of training samples was not done correctly. This caused problems also in parameter selection. It's likely that multiple patches will be mapped to the same visual words, so we will not map an image to all visual words.

\item How did you select the parameters for your model? Which are the
  most important parameters of your model? \\ \\
\textbf{Answer}:

We considered three parameters for the OCP/SGD solution: 
\begin{itemize}
\item $K$
\item $Lambda$ 
\item the learning rate $\eta$.
\end{itemize}

We tried to vary in a grid search manner possible values for the parameters, taking into account all possible combinations with: $K \in \{32, 64, 120\}, Lambda \in \{0.03, 0.1, 0.3\}$ and $\eta \in \{0.03, 0.1, 0.3\}$. We used cross-validation to determine the best combination of parameter values.

\end{enumerate}

\section{Recommender Systems}

\begin{enumerate}
\item Which algorithm did you implement? What was your motivation? \\ \\
\textbf{Answer}:

\item How did you select the parameters for your model? \\ \\
\textbf{Answer}:

\item Does the performance measured in CTR increase monotonically during the
execution of your algorithm? Why? \\ \\
\textbf{Answer}:

\end{enumerate}

\end{document}
